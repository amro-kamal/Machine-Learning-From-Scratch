{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convolution from scratch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW5WG2XhcDOU"
      },
      "source": [
        "import torch\n",
        "from torch.nn import functional as F\n",
        "\n",
        "def conv_forward_naive(x, w, b, conv_param):\n",
        "    \"\"\"\n",
        "    A naive Python implementation of a convolution.\n",
        "    The input consists of an image tensor with height H and\n",
        "    width W. We convolve each input with a filter F, where the filter\n",
        "    has height HH and width WW.\n",
        "    Input:\n",
        "    - x: Input data of shape (B , C ,H, W)\n",
        "    - w: Filter weights of shape (C_out , C , HH, WW)\n",
        "    - b: Bias for filter\n",
        "    - conv_param: A dictionary with the following keys:\n",
        "      - 'stride': The number of pixels between adjacent receptive fields in the\n",
        "        horizontal and vertical directions.\n",
        "      - 'pad': The number of pixels that will be used to zero-pad the input. \n",
        "        \n",
        "    During padding, 'pad' zeros should be placed symmetrically (i.e equally on both sides)\n",
        "    along the height and width axes of the input. Be careful not to modfiy the original\n",
        "    input x directly.\n",
        "    Returns an array.\n",
        "    - out: Output data, of shape (H', W') where H' and W' are given by\n",
        "      H' = 1 + (H + 2 * pad - HH) / stride\n",
        "      W' = 1 + (W + 2 * pad - WW) / stride\n",
        "    \"\"\"\n",
        "\n",
        "    \n",
        "    pad , stride = conv_param['pad'] , conv_param['stride']\n",
        "    \n",
        "    B , input_channels , H , W = x.shape\n",
        "    C_out , filter_channels, filter_height , filter_width =w.shape\n",
        "    stride , pad = conv_param['stride'] , conv_param['pad']\n",
        "    assert input_channels == filter_channels , 'the input and the filters must have the same number of channels'\n",
        "\n",
        "    # Check dimensions.\n",
        "    assert (W + 2 * pad - filter_width) % stride == 0, 'width does not work'\n",
        "    assert (H + 2 * pad - filter_height) % stride == 0, 'height does not work'\n",
        "\n",
        "    H_o  = 1 + int((W + 2 * pad - filter_height) / stride)\n",
        "    W_o= 1 + int((W + 2 * pad - filter_height) / stride)\n",
        "\n",
        "    out = torch.randn(B,C_out , H_o , W_o)\n",
        "    # print('output shape ',out.shape)\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the convolutional forward pass.                         #\n",
        "    # Hint: you can use the function torch.nn.functional.pad for padding.     #\n",
        "    padding = (\n",
        "        pad,pad,   \n",
        "        pad,pad,\n",
        "    )\n",
        "    x_pad = F.pad(x ,padding)\n",
        "\n",
        "    def convolve(x,k):\n",
        "      conv = torch.sum( x * k , (1,2,3))\n",
        "      return conv\n",
        "    for e in range(B):\n",
        "      for i in range(H_o):\n",
        "        for j in range(W_o):\n",
        "          # print('i ,j ',i , j)\n",
        "          k=filter_height\n",
        "          # print('k= ' , k)\n",
        "          \n",
        "          out[e, : ,i,j]= convolve( x_pad[e , : , i*stride:i*stride+k , j*stride:j*stride+k] , w) + b #all batch , all channels , window , window\n",
        "\n",
        "    return out\n",
        "    ###########################################################################\n",
        "    \n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_avu99QicFoX",
        "outputId": "a8508e69-c271-418b-b7f1-029700d1281f"
      },
      "source": [
        "\n",
        "# Make convolution module.\n",
        "w_shape = (3, 3, 4, 4)\n",
        "w = torch.linspace(-0.2, 0.3, steps=torch.prod(torch.tensor(w_shape))).reshape(w_shape)\n",
        "b = torch.linspace(-0.1, 0.2, steps=3)\n",
        "\n",
        "# Compute output of module and compare against reference values.\n",
        "x_shape = (2, 3, 4, 4)\n",
        "x = torch.linspace(-0.1, 0.5, steps=torch.prod(torch.tensor(x_shape))).reshape(x_shape)\n",
        "out = conv_forward_naive(x, w, b, {'stride': 2, 'pad': 1})\n",
        "\n",
        "\n",
        "correct_out = torch.tensor([[[[-0.08759809, -0.10987781],\n",
        "                              [-0.18387192, -0.2109216 ]],\n",
        "                             [[ 0.21027089,  0.21661097],\n",
        "                              [ 0.22847626,  0.23004637]],\n",
        "                             [[ 0.50813986,  0.54309974],\n",
        "                              [ 0.64082444,  0.67101435]]],\n",
        "                            [[[-0.98053589, -1.03143541],\n",
        "                              [-1.19128892, -1.24695841]],\n",
        "                             [[ 0.69108355,  0.66880383],\n",
        "                              [ 0.59480972,  0.56776003]],\n",
        "                             [[ 2.36270298,  2.36904306],\n",
        "                              [ 2.38090835,  2.38247847]]]])\n",
        "\n",
        "print('---'*10)\n",
        "print('out shape' , out.shape)\n",
        "print('correct_out shape' , correct_out.shape)\n",
        "\n",
        "\n",
        "print('---'*10)\n",
        "\n",
        "# Compare your output to ours; difference should be around e-8\n",
        "print('Testing conv_forward_naive')\n",
        "rel_error = ((out - correct_out) / (out + correct_out + 1e-6)).mean()\n",
        "print('difference: ', rel_error)\n",
        "if abs(rel_error) < 1e-6:\n",
        "    print('Nice work! Your implementation of a convolution layer works correctly.')\n",
        "else:\n",
        "    print('Something is wrong. The output was expected to be \\n{} \\nbut it was \\n{}'.format(correct_out, out))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "out shape torch.Size([2, 3, 2, 2])\n",
            "correct_out shape torch.Size([2, 3, 2, 2])\n",
            "------------------------------\n",
            "Testing conv_forward_naive\n",
            "difference:  tensor(2.8497e-08)\n",
            "Nice work! Your implementation of a convolution layer works correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f50bk7fcQdP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}